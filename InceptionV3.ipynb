{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gMa7O-2Zsz9m",
    "outputId": "f1e146df-d0fb-4e46-c835-f5a93f9ab68c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, concatenate\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eqInVBetOW7"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "n_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9BldQV1tcSd"
   },
   "outputs": [],
   "source": [
    "def InceptionV3_block1():\n",
    "    def f(x):\n",
    "        b1 = Convolution2D(64, (1,1), strides=2, padding='same')(x)\n",
    "        b1 = BatchNormalization()(b1)\n",
    "        b1 = Activation('relu')(b1)\n",
    "\n",
    "        b2 = Convolution2D(48, (1,1))(x)\n",
    "        b2 = BatchNormalization()(b2)\n",
    "        b2 = Activation('relu')(b2)\n",
    "        b2 = Convolution2D(96, (3,3), strides=2, padding='same')(b2)\n",
    "        b2 = BatchNormalization()(b2)\n",
    "        b2 = Activation('relu')(b2)\n",
    "\n",
    "\n",
    "        b3 = AveragePooling2D(pool_size=(3, 3), strides=2,  padding='same')(x)\n",
    "        b3 = Convolution2D(64, (3,3), padding='same')(b3)\n",
    "        b3 = BatchNormalization()(b3)\n",
    "        b3 = Activation('relu')(b3)\n",
    "\n",
    "        b4 = Convolution2D(64, (1,1))(x)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "        b4 = Convolution2D(96, (3,3), padding='same')(b4)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "        b4 = Convolution2D(32, (3,3),strides=2, padding='same')(b4)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "\n",
    "        output = concatenate([b1, b2, b3, b4], axis=-1)\n",
    "        return output\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-TocomMvAVk"
   },
   "outputs": [],
   "source": [
    "def InceptionV3_block2():\n",
    "    def f(x):\n",
    "        b1 = Convolution2D(64, (1,1), strides=2,  padding='same')(x)\n",
    "        b1 = BatchNormalization()(b1)\n",
    "        b1 = Activation('relu')(b1)\n",
    "\n",
    "        b2 = Convolution2D(48, (1,1))(x)\n",
    "        b2 = BatchNormalization()(b2)\n",
    "        b2 = Activation('relu')(b2)\n",
    "        b2 = Convolution2D(96, (3,3), strides=2,  padding='same')(b2)\n",
    "        b2 = BatchNormalization()(b2)\n",
    "        b2 = Activation('relu')(b2)\n",
    "\n",
    "\n",
    "        b3 = AveragePooling2D(pool_size=(3, 3), strides=2,  padding='same')(x)\n",
    "        b3 = Convolution2D(64, (3,3), padding='same')(b3)\n",
    "        b3 = BatchNormalization()(b3)\n",
    "        b3 = Activation('relu')(b3)\n",
    "\n",
    "        b4 = Convolution2D(64, (1,1))(x)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "        b4 = Convolution2D(96, (3,3), padding='same')(b4)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "        b4 = Convolution2D(64, (3,3),strides=2, padding='same')(b4)\n",
    "        b4 = BatchNormalization()(b4)\n",
    "        b4 = Activation('relu')(b4)\n",
    "\n",
    "        output = concatenate([b1, b2, b3, b4], axis=-1)\n",
    "        return output\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2040
    },
    "colab_type": "code",
    "id": "tkQi4cAjvtJc",
    "outputId": "39627233-f417-47c4-c74d-c7054bdfaf6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 32)   128         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 64)     2112        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 48)     1584        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 96)     55392       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 48)     192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 96)     384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 48)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 4, 4, 32)     0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 96)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 64)     2112        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 96)     41568       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 64)     18496       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 32)     27680       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 64)     256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 96)     384         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 64)     256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 32)     128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 64)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 32)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 256)    0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 64)     16448       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 4, 4, 64)     256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 48)     12336       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 96)     55392       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 4, 48)     192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 96)     384         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 48)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 2, 2, 256)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 96)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 64)     16448       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 2, 2, 96)     41568       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 2, 2, 64)     147520      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 2, 2, 64)     55360       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 2, 64)     256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2, 2, 96)     384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2, 2, 64)     256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 2, 2, 64)     256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 64)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 96)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 64)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2, 2, 288)    0           activation_34[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 288)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2890        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 501,002\n",
      "Trainable params: 499,018\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def InceptionV3():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = Convolution2D(32, (1,1), strides=2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding='same')(x)\n",
    "  \n",
    "    x = InceptionV3_block1()(x)\n",
    "    x = InceptionV3_block2()(x)\n",
    "  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = InceptionV3()\n",
    "adam = Adam()\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "b72qJpuAyWZB",
    "outputId": "8570bb2c-b329-462f-f5ca-3673af2868e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 38s 956us/step - loss: 1.4259 - acc: 0.4887 - val_loss: 1.2818 - val_acc: 0.5380\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 33s 832us/step - loss: 1.1555 - acc: 0.5886 - val_loss: 1.2218 - val_acc: 0.5667\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 33s 833us/step - loss: 1.0295 - acc: 0.6366 - val_loss: 1.2112 - val_acc: 0.5718\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 33s 835us/step - loss: 0.9211 - acc: 0.6744 - val_loss: 1.1393 - val_acc: 0.5988\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 33s 833us/step - loss: 0.8319 - acc: 0.7075 - val_loss: 1.3095 - val_acc: 0.5690\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 33s 832us/step - loss: 0.7401 - acc: 0.7400 - val_loss: 1.1308 - val_acc: 0.6166\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 33s 830us/step - loss: 0.6493 - acc: 0.7722 - val_loss: 1.1169 - val_acc: 0.6276\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 34s 838us/step - loss: 0.5658 - acc: 0.8029 - val_loss: 1.1733 - val_acc: 0.6245\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 33s 832us/step - loss: 0.4901 - acc: 0.8294 - val_loss: 1.3104 - val_acc: 0.6012\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 33s 835us/step - loss: 0.4128 - acc: 0.8577 - val_loss: 1.2887 - val_acc: 0.6085\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "h = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOojPeus3PkD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionV3",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
